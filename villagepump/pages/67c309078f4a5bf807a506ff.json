{
  "id": "67c309078f4a5bf807a506ff",
  "title": "Tay",
  "created": 1740835111,
  "updated": 1745122649,
  "lines": [
    {
      "id": "67c309078f4a5bf807a506ff",
      "text": "Tay",
      "userId": "661b6e882a96e9002371b3c2",
      "created": 1740835111,
      "updated": 1740835111
    },
    {
      "id": "67c309c071b3c20000d8d971",
      "text": "2016年の米[Microsoft]の大[炎上][AI]",
      "userId": "661b6e882a96e9002371b3c2",
      "created": 1740835264,
      "updated": 1745122636
    },
    {
      "id": "67c309d771b3c20000d8d972",
      "text": "Twitter上で活動を行っていた",
      "userId": "661b6e882a96e9002371b3c2",
      "created": 1740835287,
      "updated": 1740835294
    },
    {
      "id": "680473dc0000000000e73c78",
      "text": "思想面でのフィルターがなかったため、ひどい発言が横行した",
      "userId": "661b6e882a96e9002371b3c2",
      "created": 1745122268,
      "updated": 1745122367
    },
    {
      "id": "680474400000000000e73c7a",
      "text": "その後、MSはAIに思想を持たせないようにした",
      "userId": "661b6e882a96e9002371b3c2",
      "created": 1745122368,
      "updated": 1745122379
    },
    {
      "id": "67c3092771b3c20000d8d96e",
      "text": "わずか16時間でサ終した",
      "userId": "661b6e882a96e9002371b3c2",
      "created": 1740835111,
      "updated": 1740835127
    },
    {
      "id": "67c3094471b3c20000d8d970",
      "text": "",
      "userId": "661b6e882a96e9002371b3c2",
      "created": 1740835141,
      "updated": 1740835141
    },
    {
      "id": "680475560000000000d918ad",
      "text": "Tayの失敗から得られた教訓は、AIに学習させる際には、学習データの品質とフィルタリングがいかに重要かということです。特に、ユーザーが積極的にAIを操作する形の場合、予測不可能な形で不適切なデータが流れ込む可能性があるため、AIの設計には倫理的なガイドラインや強力な監視機構が不可欠だということが強調されました。",
      "userId": "661b6e882a96e9002371b3c2",
      "created": 1745122647,
      "updated": 1745122647
    },
    {
      "id": "680475560000000000d918af",
      "text": "その後、Microsoftをはじめとする多くの企業は、AIの言動や発言に対する倫理的なフィルタリングを強化し、AIが社会的に受け入れられる形で運用されるような取り組みを進めてきました。",
      "userId": "661b6e882a96e9002371b3c2",
      "created": 1745122647,
      "updated": 1745122647
    }
  ]
}